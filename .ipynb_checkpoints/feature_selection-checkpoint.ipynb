{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#done\n",
    "def convert_to_float(not_float):\n",
    "    float_list = []\n",
    "    for i in not_float:\n",
    "            float_list.append([float(j) for j in i])\n",
    "    return float_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: split  test with training set\n",
    "def process_file(raw_file_name):\n",
    "    raw_file = open(raw_file_name, 'r')\n",
    "    str_data = []\n",
    "    with open(raw_file_name) as file:\n",
    "        raw_data = file.readlines()\n",
    "    str_data = [i.split() for i in raw_data]\n",
    "    return convert_to_float(str_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done\n",
    "def take_out_classification(data):\n",
    "    classfication = []\n",
    "    for i in data:\n",
    "        classfication.append(i.pop(0))\n",
    "    return classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done\n",
    "def add_back_classification(data, list_of_classfication):\n",
    "    for i in range(0, len(data)):\n",
    "        data[i].insert(0, float(list_of_classfication[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done\n",
    "def getmean(data, features, instances):\n",
    "    mean_list = []\n",
    "    column = 0\n",
    "    #classif = take_out_classification(data)\n",
    "    for i in range(features):\n",
    "        mean = sum(row[column] for row in data)/instances\n",
    "        column = column + 1\n",
    "        mean_list.append(mean)\n",
    "    #add_back_classification(data, classif)\n",
    "    return mean_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done\n",
    "import math\n",
    "def getstd(data, mean_list, features, instances):\n",
    "    standard_d_list = []\n",
    "    #classif = take_out_classification(data)\n",
    "    mean_list = getmean(data, features, instances)\n",
    "    for i in range(features):\n",
    "        standard_d = math.sqrt((sum(pow((row[i] - mean_list[i]), 2) for row in data)) / instances)\n",
    "        standard_d_list.append(standard_d)\n",
    "    #add_back_classification(data, classif)\n",
    "    #df = pd.DataFrame(standard_d_list)\n",
    "    #print(df)\n",
    "    return standard_d_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done\n",
    "def scale(data):\n",
    "    classif = take_out_classification(data)\n",
    "    features = len(data[0])\n",
    "    instances = len(data)\n",
    "    #print(instances)\n",
    "    mean_list = getmean(data, features , instances)\n",
    "    standard_d_list = getstd(data, mean_list, features, instances )\n",
    "    #df  = pd.DataFrame(data)\n",
    "    #print(df)\n",
    "    \n",
    "    for i in range(0, instances):\n",
    "        for j in range(features):\n",
    "            #print(\"in loop\")\n",
    "            #print(data[i][j])\n",
    "            data[i][j] = (data[i][j] - mean_list[j])/ standard_d_list[j]\n",
    "    add_back_classification(data, classif)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    0         1         2         3         4         5         6         7   \\\n",
      "0  2.0  2.862132  3.834596  3.851024  2.535483  1.974341  2.466221  1.095809   \n",
      "1  1.0  2.078912  3.384557  4.088998  3.658901  3.336261  4.938376  1.988108   \n",
      "2  2.0  2.204019  1.271734  3.189046  2.933074  3.520601  2.542561  2.263089   \n",
      "3  1.0  2.204019  1.271734  3.189046  2.933074  3.520601  2.542561  2.263089   \n",
      "4  2.0  3.217470  4.141943  1.686134  3.002474  4.163254  2.021311  3.750022   \n",
      "\n",
      "         8         9         10  \n",
      "0  2.180104  2.633061  3.148389  \n",
      "1  3.600924  3.120524  1.396510  \n",
      "2  3.634898  3.501847  4.183576  \n",
      "3  3.634898  3.501847  4.183576  \n",
      "4  2.461549  2.410751  2.338304  \n",
      "    0         1         2         3         4         5         6         7   \\\n",
      "0  2.0  0.780949  0.839207  0.776422 -1.315122 -1.842117 -0.420668 -1.376895   \n",
      "1  1.0 -0.972539  0.480773  1.060605  1.781452  0.046098  1.964636 -0.332355   \n",
      "2  2.0 -0.692449 -1.201987 -0.014096 -0.219208  0.301674 -0.347010 -0.010459   \n",
      "3  1.0 -0.692449 -1.201987 -0.014096 -0.219208  0.301674 -0.347010 -0.010459   \n",
      "4  2.0  1.576488  1.083994 -1.808836 -0.027914  1.192671 -0.849947  1.730168   \n",
      "\n",
      "         8         9         10  \n",
      "0 -1.431124 -0.898147  0.091127  \n",
      "1  0.773379  0.194897 -1.532625  \n",
      "2  0.826092  1.049942  1.050604  \n",
      "3  0.826092  1.049942  1.050604  \n",
      "4 -0.994441 -1.396635 -0.659711  \n"
     ]
    }
   ],
   "source": [
    "trainSet = [[2.0000000e+00 ,2.8621318e+00,   3.8345958e+00,   3.8510244e+00,   2.5354832e+00,   1.9743413e+00,   2.4662208e+00,   1.0958087e+00,   2.1801037e+00,   2.6330608e+00,   3.1483889e+00], [1.0000000e+00  ,2.0789125e+00, 3.3845572e+00   ,4.0889981e+00   ,3.6589007e+00   ,3.3362607e+00   ,4.9383758e+00   ,1.9881081e+00   ,3.6009237e+00   ,3.1205240e+00  ,1.3965097e+00], [ 2.0000000e+00, 2.2040188e+00,   1.2717340e+00,   3.1890461e+00,   2.9330737e+00,   3.5206010e+00,   2.5425605e+00,   2.2630886e+00,   3.6348978e+00,   3.5018469e+00,   4.1835761e+00], [1.0000000e+00, 2.2040188e+00, 1.2717340e+00, 3.1890461e+00, 2.9330737e+00, 3.5206010e+00, 2.5425605e+00, 2.2630886e+00, 3.6348978e+00, 3.5018469e+00, 4.1835761e+00], [2.0000000e+00  , 3.2174703e+00  , 4.1419433e+00  , 1.6861336e+00 ,  3.0024740e+00  , 4.1632536e+00  , 2.0213114e+00  , 3.7500223e+00  , 2.4615493e+00 ,  2.4107511e+00 ,2.3383039e+00]]\n",
    "\n",
    "df  = pd.DataFrame(trainSet)\n",
    "print(df)\n",
    "trainSet = scale(trainSet)\n",
    "df  = pd.DataFrame(trainSet)\n",
    "print(df)\n",
    "#print(len(trainSet[0]) - 1)\n",
    "#print(len(trainSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "me \n",
      "[[2.0, 0.9999999999999993, 1.0, 0.9999999999999993, -0.9999999999999989, -0.9999999999999999, -1.0, -1.0, -1.0, -0.9999999999999994, -1.0000000000000004], [1.0, -1.0000000000000007, -1.0, -1.0000000000000007, 1.000000000000001, 1.0000000000000002, 1.0, 1.0, 1.0, 1.0000000000000004, 0.9999999999999996]]\n"
     ]
    }
   ],
   "source": [
    "data1 = [[ 2.0000000e+00 ,2.8621318e+00,   3.8345958e+00,   3.8510244e+00,   2.5354832e+00,   1.9743413e+00,   2.4662208e+00,   1.0958087e+00,   2.1801037e+00,   2.6330608e+00,   3.1483889e+00],  [1.0000000e+00, 2.2040188e+00,   1.2717340e+00,   3.1890461e+00,   2.9330737e+00,   3.5206010e+00,   2.5425605e+00,   2.2630886e+00,   3.6348978e+00,   3.5018469e+00,   4.1835761e+00]]\n",
    "\n",
    "print(\"me \")\n",
    "#print(data1)\n",
    "#print(getmean(data1, 2, 2))\n",
    "#print(getstd(data1,getmean(data1, 2, 2),2, 2))\n",
    "print(scale(data1))\n",
    "#print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#done\n",
    "def euclideanDistance(instance_a, instance_b, features):\n",
    "    #remove classfication for calculation\n",
    "    #print(instance_a)\n",
    "    classification_1 = instance_a.pop(0)\n",
    "    classification_2 = instance_b.pop(0)\n",
    "    \n",
    "    distance = 0\n",
    "    #print(repr(instance_a) +\"\\n\"+ repr(instance_b))\n",
    "    for i in range(len(features)):\n",
    "        #print(instance_b)\n",
    "        #print(features[i])\n",
    "        #print(instance_b[features[i]])\n",
    "       # print(\"instance a = \" +  repr(instance_a[i]) + \" and instance b = \" +  repr(instance_b[i]))\n",
    "        distance = distance + pow((instance_a[features[i]] - instance_b[features[i]]), 2)\n",
    "       # print(\"and the distance is: \" + repr(distance) + \"\\n\")\n",
    "    \n",
    "    #add classification back\n",
    "    instance_a.insert(0, classification_1)\n",
    "    instance_b.insert(0, classification_2)\n",
    "    return math.sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance: 0.7832192999999998\n"
     ]
    }
   ],
   "source": [
    "data1 = [ 2.0000000e+00 ,2.8621318e+00,   3.8345958e+00,   3.8510244e+00,   2.5354832e+00,   1.9743413e+00,   2.4662208e+00,   1.0958087e+00,   2.1801037e+00,   2.6330608e+00,   3.1483889e+00]\n",
    "data2 = [2.0000000e+00, 2.0789125e+00, 3.3845572e+00   ,4.0889981e+00   ,3.6589007e+00   ,3.3362607e+00   ,4.9383758e+00   ,1.9881081e+00   ,3.6009237e+00   ,3.1205240e+00  ,1.3965097e+00]\n",
    "distance = euclideanDistance(data1, data2, [0])\n",
    "print( 'Distance: ' + repr(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nearest_neighbor(data, test, features):\n",
    "    best_neighbor = [-1, -1]\n",
    "    distance = float('inf')\n",
    "    test_distance = float('inf')\n",
    "    for i in data:\n",
    "        if len(features) > 0:\n",
    "            test_distance = euclideanDistance(i, test, features)\n",
    "        if test_distance < distance:\n",
    "            distance = test_distance\n",
    "            #print(i[0])\n",
    "            best_neighbor[0] = i[0]\n",
    "            #print(test_distance)\n",
    "            best_neighbor[1]= test_distance\n",
    "    return best_neighbor\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1, -1]\n"
     ]
    }
   ],
   "source": [
    "trainSet = [[2.0000000e+00 ,2.8621318e+00,   3.8345958e+00,   3.8510244e+00,   2.5354832e+00,   1.9743413e+00,   2.4662208e+00,   1.0958087e+00,   2.1801037e+00,   2.6330608e+00,   3.1483889e+00], [1.0000000e+00  ,2.0789125e+00, 3.3845572e+00   ,4.0889981e+00   ,3.6589007e+00   ,3.3362607e+00   ,4.9383758e+00   ,1.9881081e+00   ,3.6009237e+00   ,3.1205240e+00  ,1.3965097e+00]]\n",
    "testInstance = [1.0000000e+00  ,2.0789125e+00, 3.3845572e+00   ,4.0889981e+00   ,3.6589007e+00   ,3.3362607e+00   ,4.9383758e+00   ,1.9881081e+00   ,3.6009237e+00   ,3.1205240e+00  ,1.3965097e+00]\n",
    "k = 1\n",
    "neighbor = nearest_neighbor(trainSet, testInstance, [])\n",
    "print(neighbor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_accuracy(data,feature_set):\n",
    "    feature = list(feature_set)\n",
    "    #print(feature)\n",
    "    accuracy = 0\n",
    "    test = []\n",
    "    neighbor = []\n",
    "    #random(data)\n",
    "    for i in range(1501):\n",
    "        np.random.shuffle(data)\n",
    "        #print(data)\n",
    "        test = data.pop(0)\n",
    "        #print(\"test \" + repr(test[0]))\n",
    "        neighbor = nearest_neighbor(data, test, feature)\n",
    "        #print(\"Neighbor \" + repr(neighbor))\n",
    "        #print(\"found \" + repr(nearest_neighbor(data, test, feature)[0]))\n",
    "        if  neighbor[0] == test[0]:\n",
    "            accuracy = accuracy + 1\n",
    "        data.append(test)\n",
    "    accuracy = accuracy/1501\n",
    "    return accuracy * 100\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "trainSet = [[2.0000000e+00 ,2.8621318e+00,   3.8345958e+00,   3.8510244e+00,   2.5354832e+00,   1.9743413e+00,   2.4662208e+00,   1.0958087e+00,   2.1801037e+00,   2.6330608e+00,   3.1483889e+00], [1.0000000e+00  ,2.0789125e+00, 3.3845572e+00   ,4.0889981e+00   ,3.6589007e+00   ,3.3362607e+00   ,4.9383758e+00   ,1.9881081e+00   ,3.6009237e+00   ,3.1205240e+00  ,1.3965097e+00], [ 2.0000000e+00, 2.2040188e+00,   1.2717340e+00,   3.1890461e+00,   2.9330737e+00,   3.5206010e+00,   2.5425605e+00,   2.2630886e+00,   3.6348978e+00,   3.5018469e+00,   4.1835761e+00], [1.0000000e+00, 2.2040188e+00, 1.2717340e+00, 3.1890461e+00, 2.9330737e+00, 3.5206010e+00, 2.5425605e+00, 2.2630886e+00, 3.6348978e+00, 3.5018469e+00, 4.1835761e+00], [2.0000000e+00  , 3.2174703e+00  , 4.1419433e+00  , 1.6861336e+00 ,  3.0024740e+00  , 4.1632536e+00  , 2.0213114e+00  , 3.7500223e+00  , 2.4615493e+00 ,  2.4107511e+00 ,2.3383039e+00]]\n",
    "accuracy = 0\n",
    "accuracy = compute_accuracy(trainSet, [])\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_selection(data):\n",
    "    features = len(data[0]) - 1\n",
    "    #print(features)\n",
    "    feature_set = set([0])\n",
    "    good_feature = 0\n",
    "    best_accuracy = compute_accuracy(data,feature_set)\n",
    "    #print(best_accuracy)\n",
    "    accuracy = 0\n",
    "    for i in range(features):\n",
    "        print(i)\n",
    "        feature_set.add(i)\n",
    "        print(\"At level \" + repr(i + 1) )\n",
    "        print(\"Using \" + repr(feature_set))\n",
    "        accuracy = compute_accuracy(data, feature_set)\n",
    "        #print(\"Current accuracy so far: \" + repr(accuracy) + \"%\")\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            print(\"Best accuracy so far: \" + repr(best_accuracy) + \"%\")\n",
    "        else:\n",
    "            print(\"(Warning, Accuracy has decreased! Continuing search in case of local maxima)\")\n",
    "            feature_set.discard(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "At level 1\n",
      "Using {0}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "1\n",
      "At level 2\n",
      "Using {1}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "2\n",
      "At level 3\n",
      "Using {2}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "3\n",
      "At level 4\n",
      "Using {3}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "4\n",
      "At level 5\n",
      "Using {4}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "5\n",
      "At level 6\n",
      "Using {5}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "6\n",
      "At level 7\n",
      "Using {6}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "7\n",
      "At level 8\n",
      "Using {7}\n",
      "Best accuracy so far: 51.299133910726184%\n",
      "8\n",
      "At level 9\n",
      "Using {7, 8}\n",
      "Best accuracy so far: 52.23184543637574%\n",
      "9\n",
      "At level 10\n",
      "Using {7, 8, 9}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainSet = [[2.0000000e+00 ,2.8621318e+00,   3.8345958e+00,   3.8510244e+00,   2.5354832e+00,   1.9743413e+00,   2.4662208e+00,   1.0958087e+00,   2.1801037e+00,   2.6330608e+00,   3.1483889e+00], [1.0000000e+00  ,2.0789125e+00, 3.3845572e+00   ,4.0889981e+00   ,3.6589007e+00   ,3.3362607e+00   ,4.9383758e+00   ,1.9881081e+00   ,3.6009237e+00   ,3.1205240e+00  ,1.3965097e+00], [ 2.0000000e+00, 2.2040188e+00,   1.2717340e+00,   3.1890461e+00,   2.9330737e+00,   3.5206010e+00,   2.5425605e+00,   2.2630886e+00,   3.6348978e+00,   3.5018469e+00,   4.1835761e+00], [1.0000000e+00, 2.2040188e+00, 1.2717340e+00, 3.1890461e+00, 2.9330737e+00, 3.5206010e+00, 2.5425605e+00, 2.2630886e+00, 3.6348978e+00, 3.5018469e+00, 4.1835761e+00], [2.0000000e+00  , 3.2174703e+00  , 4.1419433e+00  , 1.6861336e+00 ,  3.0024740e+00  , 4.1632536e+00  , 2.0213114e+00  , 3.7500223e+00  , 2.4615493e+00 ,  2.4107511e+00 ,2.3383039e+00]]\n",
    "\n",
    "#df  = pd.DataFrame(trainSet)\n",
    "#print(df)\n",
    "trainSet = scale(trainSet)\n",
    "#print(trainSet)\n",
    "\n",
    "#df  = pd.DataFrame(trainSet)\n",
    "#print(df)\n",
    "\n",
    "forward_selection(trainSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "At level 1\n",
      "Using {0}\n",
      "Best accuracy so far: 61.892071952031976%\n",
      "At level 2\n",
      "Using {0, 1}\n",
      "Best accuracy so far: 62.891405729513664%\n",
      "At level 3\n",
      "Using {0, 1, 2}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "At level 4\n",
      "Using {0, 1, 3}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "At level 5\n",
      "Using {0, 1, 4}\n",
      "Best accuracy so far: 74.21718854097269%\n",
      "At level 6\n",
      "Using {0, 1, 4, 5}\n",
      "Best accuracy so far: 79.54696868754164%\n",
      "At level 7\n",
      "Using {0, 1, 4, 5, 6}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "At level 8\n",
      "Using {0, 1, 4, 5, 7}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "At level 9\n",
      "Using {0, 1, 4, 5, 8}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n",
      "At level 10\n",
      "Using {0, 1, 4, 5, 9}\n",
      "(Warning, Accuracy has decreased! Continuing search in case of local maxima)\n"
     ]
    }
   ],
   "source": [
    "raw_file_open = 'CS170Smalltestdata__37.txt'\n",
    "data = process_file(raw_file_open)\n",
    "forward_selection(data)\n",
    "\n",
    "#nearest_neighbor(data, test, )\n",
    "#print(data)\n",
    "#print(data[0][1])\n",
    "#print(data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
